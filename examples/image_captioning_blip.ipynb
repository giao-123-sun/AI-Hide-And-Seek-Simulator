{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prwiIBb1lin_"
      },
      "source": [
        "# Fine-tune BLIP using Hugging Face `transformers` and `datasets` ðŸ¤—\n",
        "\n",
        "This tutorial is largely based from the [GiT tutorial](https://colab.research.google.com/drive/1HLxgrG7xZJ9FvXckNG61J72FkyrbqKAA?usp=sharing) on how to fine-tune GiT on a custom image captioning dataset. Here we will use a dummy dataset of [football players](https://huggingface.co/datasets/ybelkada/football-dataset) âš½ that is uploaded on the Hub. The images have been manually selected together with the captions.\n",
        "Check the ðŸ¤— [documentation](https://huggingface.co/docs/datasets/image_dataset) on how to create and upload your own image-text dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KNaYcxCqn8t"
      },
      "source": [
        "## Set-up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqrW65lfqhhJ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTI8wKxgql9i"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmUzlJNHq0CK"
      },
      "source": [
        "## Load the image captioning dataset\n",
        "\n",
        "Let's load the image captioning dataset, you just need few lines of code for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwkaKQKLs8vT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"ybelkada/football-dataset\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y52jgY9-mhvJ"
      },
      "source": [
        "Let's retrieve the caption of the first example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4WLPzYlutg6"
      },
      "outputs": [],
      "source": [
        "dataset[0][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukZ5x_Sumn1f"
      },
      "source": [
        "And the corresponding image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxoDUv5ymqBJ"
      },
      "outputs": [],
      "source": [
        "dataset[0][\"image\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSWkkqiKqrhv"
      },
      "source": [
        "## Create PyTorch Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBjZLhLFmwwv"
      },
      "source": [
        "The lines below are entirely copied from the original notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93od71o_qq_V"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImageCaptioningDataset(Dataset):\n",
        "    def __init__(self, dataset, processor):\n",
        "        self.dataset = dataset\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        encoding = self.processor(images=item[\"image\"], text=item[\"text\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # remove batch dimension\n",
        "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
        "        return encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX6Nv8aEm0yk"
      },
      "source": [
        "## Load model and processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLhbdBLNxBuF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXlkVag6nDx3"
      },
      "source": [
        "Now that we have loaded the processor, let's load the dataset and the dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxajSwc3w-LU"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageCaptioningDataset(dataset, processor)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_CyLSgBxyL2"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cVsJdd2nV1S"
      },
      "source": [
        "Let's train the model! Run the simply the cell below for training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cCVhsmJxxjH",
        "outputId": "b1d3defb-8c28-4101-e50b-ad5227e9b1cf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4169383787.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=use_amp)\n",
            "/tmp/ipython-input-4169383787.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=use_amp):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 | step 50 | train_loss(avg50)=2.1184\n",
            "Epoch 1/5 | step 100 | train_loss(avg50)=2.1226\n",
            "Epoch 1/5 | step 150 | train_loss(avg50)=2.0402\n",
            "Epoch 1/5 | step 200 | train_loss(avg50)=2.1251\n",
            "Epoch 1/5 | step 250 | train_loss(avg50)=2.0582\n",
            "Epoch 1/5 | step 300 | train_loss(avg50)=2.0800\n",
            "Epoch 1/5 | step 350 | train_loss(avg50)=2.0489\n",
            "Epoch 1/5 | step 400 | train_loss(avg50)=2.0886\n",
            "Epoch 1/5 | step 450 | train_loss(avg50)=2.0177\n",
            "Epoch 1/5 | step 500 | train_loss(avg50)=2.1440\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 500 | BLEU=0.2432 | ROUGE-L=0.5098\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is jumping over a log.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is hanging from a rope.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child are sitting in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 550 | train_loss(avg50)=2.1069\n",
            "Epoch 1/5 | step 600 | train_loss(avg50)=2.0110\n",
            "Epoch 1/5 | step 650 | train_loss(avg50)=2.0723\n",
            "Epoch 1/5 | step 700 | train_loss(avg50)=2.0816\n",
            "Epoch 1/5 | step 750 | train_loss(avg50)=2.0576\n",
            "Epoch 1/5 | step 800 | train_loss(avg50)=2.0469\n",
            "Epoch 1/5 | step 850 | train_loss(avg50)=2.0151\n",
            "Epoch 1/5 | step 900 | train_loss(avg50)=2.1261\n",
            "Epoch 1/5 | step 950 | train_loss(avg50)=1.9971\n",
            "Epoch 1/5 | step 1000 | train_loss(avg50)=1.9785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 1000 | BLEU=0.2432 | ROUGE-L=0.5110\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a log.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man is rock climbing.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man in a life vest is paddling a yellow kayak with a child in a life vest.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 1050 | train_loss(avg50)=2.0963\n",
            "Epoch 1/5 | step 1100 | train_loss(avg50)=2.0201\n",
            "Epoch 1/5 | step 1150 | train_loss(avg50)=2.0324\n",
            "Epoch 1/5 | step 1200 | train_loss(avg50)=1.9784\n",
            "Epoch 1/5 | step 1250 | train_loss(avg50)=2.0529\n",
            "Epoch 1/5 | step 1300 | train_loss(avg50)=2.0851\n",
            "Epoch 1/5 | step 1350 | train_loss(avg50)=1.9724\n",
            "Epoch 1/5 | step 1400 | train_loss(avg50)=2.1025\n",
            "Epoch 1/5 | step 1450 | train_loss(avg50)=2.0782\n",
            "Epoch 1/5 | step 1500 | train_loss(avg50)=2.0392\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 1500 | BLEU=0.2310 | ROUGE-L=0.4993\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is playing with a large log.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue shirt and black pants is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a boy in a yellow kayak paddles another boy in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 1550 | train_loss(avg50)=2.1115\n",
            "Epoch 1/5 | step 1600 | train_loss(avg50)=2.0294\n",
            "Epoch 1/5 | step 1650 | train_loss(avg50)=1.9937\n",
            "Epoch 1/5 | step 1700 | train_loss(avg50)=1.9927\n",
            "Epoch 1/5 | step 1750 | train_loss(avg50)=1.9616\n",
            "Epoch 1/5 | step 1800 | train_loss(avg50)=2.0451\n",
            "Epoch 1/5 | step 1850 | train_loss(avg50)=1.9569\n",
            "Epoch 1/5 | step 1900 | train_loss(avg50)=1.9973\n",
            "Epoch 1/5 | step 1950 | train_loss(avg50)=1.9798\n",
            "Epoch 1/5 | step 2000 | train_loss(avg50)=2.1012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 2000 | BLEU=0.2539 | ROUGE-L=0.5015\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is running across a branch.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket and red helmet is rock climbing.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a boy in a yellow kayak is paddling through the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 2050 | train_loss(avg50)=2.0411\n",
            "Epoch 1/5 | step 2100 | train_loss(avg50)=2.0008\n",
            "Epoch 1/5 | step 2150 | train_loss(avg50)=2.0417\n",
            "Epoch 1/5 | step 2200 | train_loss(avg50)=1.9902\n",
            "Epoch 1/5 | step 2250 | train_loss(avg50)=2.0033\n",
            "Epoch 1/5 | step 2300 | train_loss(avg50)=2.0001\n",
            "Epoch 1/5 | step 2350 | train_loss(avg50)=1.9057\n",
            "Epoch 1/5 | step 2400 | train_loss(avg50)=1.9821\n",
            "Epoch 1/5 | step 2450 | train_loss(avg50)=2.0008\n",
            "Epoch 1/5 | step 2500 | train_loss(avg50)=2.0066\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 2500 | BLEU=0.2451 | ROUGE-L=0.5166\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog jumps over a log in the woods.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person wearing a blue jacket is hanging from a rope in the snow.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man in a yellow kayak on a lake.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 2550 | train_loss(avg50)=1.9062\n",
            "Epoch 1/5 | step 2600 | train_loss(avg50)=1.9978\n",
            "Epoch 1/5 | step 2650 | train_loss(avg50)=2.0170\n",
            "Epoch 1/5 | step 2700 | train_loss(avg50)=1.9194\n",
            "Epoch 1/5 | step 2750 | train_loss(avg50)=1.9755\n",
            "Epoch 1/5 | step 2800 | train_loss(avg50)=1.9995\n",
            "Epoch 1/5 | step 2850 | train_loss(avg50)=1.9635\n",
            "Epoch 1/5 | step 2900 | train_loss(avg50)=1.9642\n",
            "Epoch 1/5 | step 2950 | train_loss(avg50)=1.9343\n",
            "Epoch 1/5 | step 3000 | train_loss(avg50)=1.8922\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 3000 | BLEU=0.2468 | ROUGE-L=0.5042\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog sits on top of a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a child in a yellow kayak paddles through the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 3050 | train_loss(avg50)=1.9438\n",
            "Epoch 1/5 | step 3100 | train_loss(avg50)=2.0618\n",
            "Epoch 1/5 | step 3150 | train_loss(avg50)=2.0080\n",
            "Epoch 1/5 | step 3200 | train_loss(avg50)=2.0367\n",
            "Epoch 1/5 | step 3250 | train_loss(avg50)=2.0762\n",
            "Epoch 1/5 | step 3300 | train_loss(avg50)=1.9362\n",
            "Epoch 1/5 | step 3350 | train_loss(avg50)=1.8915\n",
            "Epoch 1/5 | step 3400 | train_loss(avg50)=1.9425\n",
            "Epoch 1/5 | step 3450 | train_loss(avg50)=1.9093\n",
            "Epoch 1/5 | step 3500 | train_loss(avg50)=2.0121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 3500 | BLEU=0.2411 | ROUGE-L=0.4991\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a large branch.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket and skis is hanging from a rope.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a young girl are riding a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 1/5 | step 3550 | train_loss(avg50)=1.8833\n",
            "Epoch 1/5 | step 3600 | train_loss(avg50)=1.9811\n",
            "Epoch 1/5 | step 3650 | train_loss(avg50)=1.9061\n",
            "Epoch 1/5 | step 3700 | train_loss(avg50)=1.8935\n",
            "Epoch 1/5 | step 3750 | train_loss(avg50)=1.9353\n",
            "Epoch 1/5 | step 3800 | train_loss(avg50)=1.8885\n",
            "Epoch 1 done in 55.37 min\n",
            "Epoch 2/5 | step 3850 | train_loss(avg50)=1.3305\n",
            "Epoch 2/5 | step 3900 | train_loss(avg50)=1.5203\n",
            "Epoch 2/5 | step 3950 | train_loss(avg50)=1.5232\n",
            "Epoch 2/5 | step 4000 | train_loss(avg50)=1.5439\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 4000 | BLEU=0.2478 | ROUGE-L=0.4968\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is laying on a large brown dog ' s back in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a young girl in a yellow kayak on the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 4050 | train_loss(avg50)=1.5751\n",
            "Epoch 2/5 | step 4100 | train_loss(avg50)=1.5481\n",
            "Epoch 2/5 | step 4150 | train_loss(avg50)=1.6048\n",
            "Epoch 2/5 | step 4200 | train_loss(avg50)=1.6204\n",
            "Epoch 2/5 | step 4250 | train_loss(avg50)=1.6296\n",
            "Epoch 2/5 | step 4300 | train_loss(avg50)=1.5731\n",
            "Epoch 2/5 | step 4350 | train_loss(avg50)=1.5829\n",
            "Epoch 2/5 | step 4400 | train_loss(avg50)=1.5631\n",
            "Epoch 2/5 | step 4450 | train_loss(avg50)=1.6150\n",
            "Epoch 2/5 | step 4500 | train_loss(avg50)=1.5574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 4500 | BLEU=0.2320 | ROUGE-L=0.4978\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a brown dog is sitting on a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: two people climbing a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a little girl are sitting in a yellow kayak in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 4550 | train_loss(avg50)=1.6364\n",
            "Epoch 2/5 | step 4600 | train_loss(avg50)=1.6152\n",
            "Epoch 2/5 | step 4650 | train_loss(avg50)=1.5811\n",
            "Epoch 2/5 | step 4700 | train_loss(avg50)=1.5300\n",
            "Epoch 2/5 | step 4750 | train_loss(avg50)=1.6308\n",
            "Epoch 2/5 | step 4800 | train_loss(avg50)=1.5894\n",
            "Epoch 2/5 | step 4850 | train_loss(avg50)=1.6517\n",
            "Epoch 2/5 | step 4900 | train_loss(avg50)=1.6371\n",
            "Epoch 2/5 | step 4950 | train_loss(avg50)=1.5711\n",
            "Epoch 2/5 | step 5000 | train_loss(avg50)=1.6161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 5000 | BLEU=0.2245 | ROUGE-L=0.4917\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog jumping over a fallen tree in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is ice climbing.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child in a yellow canoe float in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 5050 | train_loss(avg50)=1.6497\n",
            "Epoch 2/5 | step 5100 | train_loss(avg50)=1.6166\n",
            "Epoch 2/5 | step 5150 | train_loss(avg50)=1.6823\n",
            "Epoch 2/5 | step 5200 | train_loss(avg50)=1.6474\n",
            "Epoch 2/5 | step 5250 | train_loss(avg50)=1.5788\n",
            "Epoch 2/5 | step 5300 | train_loss(avg50)=1.6249\n",
            "Epoch 2/5 | step 5350 | train_loss(avg50)=1.6544\n",
            "Epoch 2/5 | step 5400 | train_loss(avg50)=1.6268\n",
            "Epoch 2/5 | step 5450 | train_loss(avg50)=1.6396\n",
            "Epoch 2/5 | step 5500 | train_loss(avg50)=1.5625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 5500 | BLEU=0.2485 | ROUGE-L=0.5057\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is climbing over a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is climbing a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child are in a yellow kayak in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 5550 | train_loss(avg50)=1.6463\n",
            "Epoch 2/5 | step 5600 | train_loss(avg50)=1.6449\n",
            "Epoch 2/5 | step 5650 | train_loss(avg50)=1.6462\n",
            "Epoch 2/5 | step 5700 | train_loss(avg50)=1.6667\n",
            "Epoch 2/5 | step 5750 | train_loss(avg50)=1.6329\n",
            "Epoch 2/5 | step 5800 | train_loss(avg50)=1.6288\n",
            "Epoch 2/5 | step 5850 | train_loss(avg50)=1.6152\n",
            "Epoch 2/5 | step 5900 | train_loss(avg50)=1.6187\n",
            "Epoch 2/5 | step 5950 | train_loss(avg50)=1.5978\n",
            "Epoch 2/5 | step 6000 | train_loss(avg50)=1.6285\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 6000 | BLEU=0.2427 | ROUGE-L=0.5020\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is standing on a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is hanging from a rope in the snow.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a little girl are kayaking in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 6050 | train_loss(avg50)=1.6260\n",
            "Epoch 2/5 | step 6100 | train_loss(avg50)=1.6063\n",
            "Epoch 2/5 | step 6150 | train_loss(avg50)=1.6850\n",
            "Epoch 2/5 | step 6200 | train_loss(avg50)=1.6845\n",
            "Epoch 2/5 | step 6250 | train_loss(avg50)=1.6565\n",
            "Epoch 2/5 | step 6300 | train_loss(avg50)=1.6242\n",
            "Epoch 2/5 | step 6350 | train_loss(avg50)=1.5977\n",
            "Epoch 2/5 | step 6400 | train_loss(avg50)=1.7141\n",
            "Epoch 2/5 | step 6450 | train_loss(avg50)=1.6519\n",
            "Epoch 2/5 | step 6500 | train_loss(avg50)=1.5834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 6500 | BLEU=0.2413 | ROUGE-L=0.4895\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is running over a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is climbing a snowy wall.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a woman and a young girl in a yellow kayak float in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 6550 | train_loss(avg50)=1.6950\n",
            "Epoch 2/5 | step 6600 | train_loss(avg50)=1.6758\n",
            "Epoch 2/5 | step 6650 | train_loss(avg50)=1.6271\n",
            "Epoch 2/5 | step 6700 | train_loss(avg50)=1.6194\n",
            "Epoch 2/5 | step 6750 | train_loss(avg50)=1.6354\n",
            "Epoch 2/5 | step 6800 | train_loss(avg50)=1.6659\n",
            "Epoch 2/5 | step 6850 | train_loss(avg50)=1.6550\n",
            "Epoch 2/5 | step 6900 | train_loss(avg50)=1.6486\n",
            "Epoch 2/5 | step 6950 | train_loss(avg50)=1.6400\n",
            "Epoch 2/5 | step 7000 | train_loss(avg50)=1.6120\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 7000 | BLEU=0.2414 | ROUGE-L=0.4999\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and tan dog is jumping over a large stick in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue shirt is climbing a snow - covered mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child in a yellow kayak in a lake.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 7050 | train_loss(avg50)=1.6171\n",
            "Epoch 2/5 | step 7100 | train_loss(avg50)=1.6654\n",
            "Epoch 2/5 | step 7150 | train_loss(avg50)=1.6210\n",
            "Epoch 2/5 | step 7200 | train_loss(avg50)=1.5846\n",
            "Epoch 2/5 | step 7250 | train_loss(avg50)=1.6140\n",
            "Epoch 2/5 | step 7300 | train_loss(avg50)=1.6672\n",
            "Epoch 2/5 | step 7350 | train_loss(avg50)=1.6262\n",
            "Epoch 2/5 | step 7400 | train_loss(avg50)=1.6136\n",
            "Epoch 2/5 | step 7450 | train_loss(avg50)=1.5835\n",
            "Epoch 2/5 | step 7500 | train_loss(avg50)=1.6274\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 7500 | BLEU=0.2599 | ROUGE-L=0.5037\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is laying on a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket climbs a snow - covered mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a boy and a girl in a yellow kayak ride through the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 2/5 | step 7550 | train_loss(avg50)=1.6706\n",
            "Epoch 2/5 | step 7600 | train_loss(avg50)=1.6339\n",
            "Epoch 2 done in 58.24 min\n",
            "Epoch 3/5 | step 7650 | train_loss(avg50)=0.9467\n",
            "Epoch 3/5 | step 7700 | train_loss(avg50)=1.2434\n",
            "Epoch 3/5 | step 7750 | train_loss(avg50)=1.2837\n",
            "Epoch 3/5 | step 7800 | train_loss(avg50)=1.2419\n",
            "Epoch 3/5 | step 7850 | train_loss(avg50)=1.2476\n",
            "Epoch 3/5 | step 7900 | train_loss(avg50)=1.3029\n",
            "Epoch 3/5 | step 7950 | train_loss(avg50)=1.2734\n",
            "Epoch 3/5 | step 8000 | train_loss(avg50)=1.2805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 8000 | BLEU=0.2473 | ROUGE-L=0.5049\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is laying on a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and child float in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 8050 | train_loss(avg50)=1.2803\n",
            "Epoch 3/5 | step 8100 | train_loss(avg50)=1.3303\n",
            "Epoch 3/5 | step 8150 | train_loss(avg50)=1.2992\n",
            "Epoch 3/5 | step 8200 | train_loss(avg50)=1.2861\n",
            "Epoch 3/5 | step 8250 | train_loss(avg50)=1.2957\n",
            "Epoch 3/5 | step 8300 | train_loss(avg50)=1.2947\n",
            "Epoch 3/5 | step 8350 | train_loss(avg50)=1.3709\n",
            "Epoch 3/5 | step 8400 | train_loss(avg50)=1.3404\n",
            "Epoch 3/5 | step 8450 | train_loss(avg50)=1.3135\n",
            "Epoch 3/5 | step 8500 | train_loss(avg50)=1.3374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 8500 | BLEU=0.2297 | ROUGE-L=0.4879\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog jumps over a fallen tree in a field of green grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man in a yellow kayak paddles through the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 8550 | train_loss(avg50)=1.3440\n",
            "Epoch 3/5 | step 8600 | train_loss(avg50)=1.3258\n",
            "Epoch 3/5 | step 8650 | train_loss(avg50)=1.3316\n",
            "Epoch 3/5 | step 8700 | train_loss(avg50)=1.3350\n",
            "Epoch 3/5 | step 8750 | train_loss(avg50)=1.3171\n",
            "Epoch 3/5 | step 8800 | train_loss(avg50)=1.3497\n",
            "Epoch 3/5 | step 8850 | train_loss(avg50)=1.3227\n",
            "Epoch 3/5 | step 8900 | train_loss(avg50)=1.3693\n",
            "Epoch 3/5 | step 8950 | train_loss(avg50)=1.3733\n",
            "Epoch 3/5 | step 9000 | train_loss(avg50)=1.3847\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 9000 | BLEU=0.2259 | ROUGE-L=0.4859\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is skiing in the snow.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child are sitting in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 9050 | train_loss(avg50)=1.3434\n",
            "Epoch 3/5 | step 9100 | train_loss(avg50)=1.3679\n",
            "Epoch 3/5 | step 9150 | train_loss(avg50)=1.3331\n",
            "Epoch 3/5 | step 9200 | train_loss(avg50)=1.3288\n",
            "Epoch 3/5 | step 9250 | train_loss(avg50)=1.3194\n",
            "Epoch 3/5 | step 9300 | train_loss(avg50)=1.3772\n",
            "Epoch 3/5 | step 9350 | train_loss(avg50)=1.3552\n",
            "Epoch 3/5 | step 9400 | train_loss(avg50)=1.3864\n",
            "Epoch 3/5 | step 9450 | train_loss(avg50)=1.3942\n",
            "Epoch 3/5 | step 9500 | train_loss(avg50)=1.3678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 9500 | BLEU=0.2450 | ROUGE-L=0.4942\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a woman and a child in a yellow kayak in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 9550 | train_loss(avg50)=1.3636\n",
            "Epoch 3/5 | step 9600 | train_loss(avg50)=1.3821\n",
            "Epoch 3/5 | step 9650 | train_loss(avg50)=1.3703\n",
            "Epoch 3/5 | step 9700 | train_loss(avg50)=1.3832\n",
            "Epoch 3/5 | step 9750 | train_loss(avg50)=1.3920\n",
            "Epoch 3/5 | step 9800 | train_loss(avg50)=1.3375\n",
            "Epoch 3/5 | step 9850 | train_loss(avg50)=1.3763\n",
            "Epoch 3/5 | step 9900 | train_loss(avg50)=1.3814\n",
            "Epoch 3/5 | step 9950 | train_loss(avg50)=1.3655\n",
            "Epoch 3/5 | step 10000 | train_loss(avg50)=1.3718\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 10000 | BLEU=0.2403 | ROUGE-L=0.5018\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is jumping over a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snow covered mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a girl are in a yellow kayak in the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 10050 | train_loss(avg50)=1.3853\n",
            "Epoch 3/5 | step 10100 | train_loss(avg50)=1.3780\n",
            "Epoch 3/5 | step 10150 | train_loss(avg50)=1.3915\n",
            "Epoch 3/5 | step 10200 | train_loss(avg50)=1.3572\n",
            "Epoch 3/5 | step 10250 | train_loss(avg50)=1.3892\n",
            "Epoch 3/5 | step 10300 | train_loss(avg50)=1.3799\n",
            "Epoch 3/5 | step 10350 | train_loss(avg50)=1.3971\n",
            "Epoch 3/5 | step 10400 | train_loss(avg50)=1.4183\n",
            "Epoch 3/5 | step 10450 | train_loss(avg50)=1.3727\n",
            "Epoch 3/5 | step 10500 | train_loss(avg50)=1.3424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL] step 10500 | BLEU=0.2403 | ROUGE-L=0.5058\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a log in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man is kayaking with a dog.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 10550 | train_loss(avg50)=1.3743\n",
            "Epoch 3/5 | step 10600 | train_loss(avg50)=1.3993\n",
            "Epoch 3/5 | step 10650 | train_loss(avg50)=1.4202\n",
            "Epoch 3/5 | step 10700 | train_loss(avg50)=1.3622\n",
            "Epoch 3/5 | step 10750 | train_loss(avg50)=1.3929\n",
            "Epoch 3/5 | step 10800 | train_loss(avg50)=1.4159\n",
            "Epoch 3/5 | step 10850 | train_loss(avg50)=1.4089\n",
            "Epoch 3/5 | step 10900 | train_loss(avg50)=1.4479\n",
            "Epoch 3/5 | step 10950 | train_loss(avg50)=1.3574\n",
            "Epoch 3/5 | step 11000 | train_loss(avg50)=1.4086\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] step 11000 | BLEU=0.2391 | ROUGE-L=0.4982\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a fallen tree in the forest.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is climbing up a snowy hill.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a woman and a child are sitting in a yellow canoe on the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 3/5 | step 11050 | train_loss(avg50)=1.3757\n",
            "Epoch 3/5 | step 11100 | train_loss(avg50)=1.3932\n",
            "Epoch 3/5 | step 11150 | train_loss(avg50)=1.3917\n",
            "Epoch 3/5 | step 11200 | train_loss(avg50)=1.4010\n",
            "Epoch 3/5 | step 11250 | train_loss(avg50)=1.4137\n",
            "Epoch 3/5 | step 11300 | train_loss(avg50)=1.4135\n",
            "Epoch 3/5 | step 11350 | train_loss(avg50)=1.4327\n",
            "Epoch 3/5 | step 11400 | train_loss(avg50)=1.3704\n",
            "Epoch 3 done in 55.22 min\n",
            "Epoch 4/5 | step 11450 | train_loss(avg50)=0.5823\n",
            "Epoch 4/5 | step 11500 | train_loss(avg50)=0.9986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] step 11500 | BLEU=0.2258 | ROUGE-L=0.4945\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a fallen tree in the grass.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket is climbing up a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a child in a life jacket in a yellow kayak on blue water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 4/5 | step 11550 | train_loss(avg50)=1.0125\n",
            "Epoch 4/5 | step 11600 | train_loss(avg50)=1.0307\n",
            "Epoch 4/5 | step 11650 | train_loss(avg50)=1.0032\n",
            "Epoch 4/5 | step 11700 | train_loss(avg50)=0.9965\n",
            "Epoch 4/5 | step 11750 | train_loss(avg50)=1.0162\n",
            "Epoch 4/5 | step 11800 | train_loss(avg50)=1.0351\n",
            "Epoch 4/5 | step 11850 | train_loss(avg50)=1.0718\n",
            "Epoch 4/5 | step 11900 | train_loss(avg50)=1.0763\n",
            "Epoch 4/5 | step 11950 | train_loss(avg50)=1.0717\n",
            "Epoch 4/5 | step 12000 | train_loss(avg50)=1.0676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] step 12000 | BLEU=0.2309 | ROUGE-L=0.4948\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog jumps over a log.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person in a blue jacket is hanging upside down in the snow.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man holds a paddle in a yellow kayak.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 4/5 | step 12050 | train_loss(avg50)=1.0422\n",
            "Epoch 4/5 | step 12100 | train_loss(avg50)=1.0340\n",
            "Epoch 4/5 | step 12150 | train_loss(avg50)=1.0773\n",
            "Epoch 4/5 | step 12200 | train_loss(avg50)=1.0883\n",
            "Epoch 4/5 | step 12250 | train_loss(avg50)=1.0874\n",
            "Epoch 4/5 | step 12300 | train_loss(avg50)=1.0819\n",
            "Epoch 4/5 | step 12350 | train_loss(avg50)=1.0704\n",
            "Epoch 4/5 | step 12400 | train_loss(avg50)=1.1069\n",
            "Epoch 4/5 | step 12450 | train_loss(avg50)=1.1172\n",
            "Epoch 4/5 | step 12500 | train_loss(avg50)=1.1355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] step 12500 | BLEU=0.2058 | ROUGE-L=0.4776\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black dog is jumping over a fallen tree.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a man in a blue jacket climbs up a snowy hill.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a man and a toddler in a yellow kayak ride through the water.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 4/5 | step 12550 | train_loss(avg50)=1.0783\n",
            "Epoch 4/5 | step 12600 | train_loss(avg50)=1.1111\n",
            "Epoch 4/5 | step 12650 | train_loss(avg50)=1.0797\n",
            "Epoch 4/5 | step 12700 | train_loss(avg50)=1.0965\n",
            "Epoch 4/5 | step 12750 | train_loss(avg50)=1.1036\n",
            "Epoch 4/5 | step 12800 | train_loss(avg50)=1.0689\n",
            "Epoch 4/5 | step 12850 | train_loss(avg50)=1.1006\n",
            "Epoch 4/5 | step 12900 | train_loss(avg50)=1.0809\n",
            "Epoch 4/5 | step 12950 | train_loss(avg50)=1.1056\n",
            "Epoch 4/5 | step 13000 | train_loss(avg50)=1.0963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] step 13000 | BLEU=0.2285 | ROUGE-L=0.4873\n",
            "  sample image: 1015584366_dfcec3c85a.jpg\n",
            "  pred: a black and white dog is jumping over a large piece of wood.\n",
            "  refs: ['A black dog leaps over a log .', 'A grey dog is leaping over a fallen tree .', 'A large black dog leaps a fallen log .', 'A mottled black and grey dog in a blue collar jumping over a fallen tree .', 'The black dog jumped the tree stump .']\n",
            "  ---\n",
            "  sample image: 102455176_5f8ead62d5.jpg\n",
            "  pred: a person wearing a blue jacket is skiing down a snowy mountain.\n",
            "  refs: ['A man uses ice picks and crampons to scale ice .', 'an ice climber in a blue jacket and black pants is scaling a frozen ice wall .', 'An ice climber scaling a frozen waterfall .', 'A person in blue and red ice climbing with two picks .', 'Climber climbing an ice wall']\n",
            "  ---\n",
            "  sample image: 1028205764_7e8df9a2ea.jpg\n",
            "  pred: a young boy and a young girl are in a yellow kayak on calm river.\n",
            "  refs: ['A man and a baby are in a yellow kayak on water .', 'A man and a little boy in blue life jackets are rowing a yellow canoe .', 'A man and child kayak through gentle waters .', 'A man and young boy ride in a yellow kayak .', 'Man and child in yellow kayak']\n",
            "  ---\n",
            "Epoch 4/5 | step 13050 | train_loss(avg50)=1.1349\n",
            "Epoch 4/5 | step 13100 | train_loss(avg50)=1.0937\n",
            "Epoch 4/5 | step 13150 | train_loss(avg50)=1.1509\n",
            "Epoch 4/5 | step 13200 | train_loss(avg50)=1.1355\n",
            "Epoch 4/5 | step 13250 | train_loss(avg50)=1.1243\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(50):\n",
        "  print(\"Epoch:\", epoch)\n",
        "  for idx, batch in enumerate(train_dataloader):\n",
        "    input_ids = batch.pop(\"input_ids\").to(device)\n",
        "    pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids,\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=input_ids)\n",
        "\n",
        "    loss = outputs.loss\n",
        "\n",
        "    print(\"Loss:\", loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNZQXZrERyQN"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWpn-q1oFu0"
      },
      "source": [
        "Let's check the results on our train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC-Fp480XAt7"
      },
      "outputs": [],
      "source": [
        "# load image\n",
        "example = dataset[0]\n",
        "image = example[\"image\"]\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P3-u0eRxmsa"
      },
      "outputs": [],
      "source": [
        "# prepare image for the model\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "pixel_values = inputs.pixel_values\n",
        "\n",
        "generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_caption)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQFcdiXlnqqu"
      },
      "source": [
        "## Load from the Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4oBAW8DnsHe"
      },
      "source": [
        "Once trained you can push the model and processor on the Hub to use them later.\n",
        "Meanwhile you can play with the model that we have fine-tuned!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrGmatasn5-B"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipForConditionalGeneration, AutoProcessor\n",
        "\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"ybelkada/blip-image-captioning-base-football-finetuned\").to(device)\n",
        "processor = AutoProcessor.from_pretrained(\"ybelkada/blip-image-captioning-base-football-finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNLKCOK2oNK2"
      },
      "source": [
        "Let's check the results on our train dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFGnjCgDoLIJ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(18, 14))\n",
        "\n",
        "# prepare image for the model\n",
        "for i, example in enumerate(dataset):\n",
        "  image = example[\"image\"]\n",
        "  inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "  pixel_values = inputs.pixel_values\n",
        "\n",
        "  generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "  generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "  fig.add_subplot(2, 3, i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(f\"Generated caption: {generated_caption}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}